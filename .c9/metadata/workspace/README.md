{"changed":true,"filter":false,"title":"README.md","tooltip":"/README.md","value":"# Data Pipeline Solution\n\n## Overview\n\n##tralalalalaalaaaaa ##\n\nData Pipeline is a self-hosted [Google App Engine] sample\napplication that enables its users to easily define and execute data flows\nacross different [Google Cloud Platform] products. It is\nintended as a reference for connecting multiple cloud services together, and as\na head start for building custom data processing solutions.\n\nCurrently, the application supports:\n\n* Reading data from [Google Cloud Storage],\n[Amazon S3] and arbitrary HTTP endpoints,\n\n* Querying data from [Google Cloud Datastore],\n\n* Transforming data on Google App Engine using the [Google App Engine Pipeline API], and\n[Google Compute Engine] using [Apache Hadoop].\n\n* Composing and storing data in Google Cloud Storage,\n\n* Loading data into [Google BigQuery]\n\n### Copyright\n\nCopyright 2013 Google Inc. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use\nthis file except in compliance with the License. You may obtain a copy of the\nLicense at\n\n[http://www.apache.org/licenses/LICENSE-2.0]\n\nUnless required by applicable law or agreed to in writing, software distributed\nunder the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\nCONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.\n\n### Disclaimer\n\nThis is not an official Google product.\n\n## Installation Guide\n\nIf you don't have it already, install the Google App Engine SDK and follow the\n[installation instructions]. As noted previously,\n*Data Pipeline* use App Engine Modules which were introduced in App Engine 1.8.3\nso you must install at least that version.\n\n### Open Source Libraries\n\nThe following packages should be installed in the same directory as this\nREADME.md file. The contents of the following code block and be copied and\npasted into shell:\n\n```shell\nmkdir third_party\n\n# dateutil\ncurl -o - http://labix.org/download/python-dateutil/python-dateutil-1.5.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/python-dateutil-1.5/dateutil dateutil)\n\n# jquery UI Layout\ncurl -o app/static/jquery.layout-latest.min.js http://layout.jquery-dev.net/lib/js/jquery.layout-latest.min.js\n\n# Google Application Utilities for Python\ncurl -o - https://google-apputils-python.googlecode.com/files/google-apputils-0.4.0.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/google-apputils-0.4.0/google/apputils google_apputils)\n\n # Rename the package so it doesn't conflict with google.appengine.\nperl -p -i~ -e 's/google\\.apputils/google_apputils/g' app/google_apputils/*.py\n\n# Mock\ncurl -o - https://pypi.python.org/packages/source/m/mock/mock-1.0.1.tar.gz#md5=c3971991738caa55ec7c356bbc154ee2 |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/mock-1.0.1 mock)\n(cd app/mock; ln -s mock.py __init__.py)\n\n# Google Cloud Storage Client\ncurl -o - https://pypi.python.org/packages/source/G/GoogleAppEngineCloudStorageClient/GoogleAppEngineCloudStorageClient-1.8.3.1.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/GoogleAppEngineCloudStorageClient-1.8.3.1/cloudstorage)\n\n# Google App Engine MapReduce\ncurl -o - https://pypi.python.org/packages/source/G/GoogleAppEngineMapReduce/GoogleAppEngineMapReduce-1.8.3.2.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/GoogleAppEngineMapReduce-1.8.3.2/mapreduce)\n\n# JSON.Minify\ncurl -o third_party/jsonminify.zip https://codeload.github.com/getify/JSON.minify/zip/master\n(cd third_party; unzip jsonminify.zip)\n(cd app; ln -s ../third_party/JSON.minify-master jsonminify)\ntouch app/jsonminify/__init__.py\n\n# parsedatetime\ncurl -o third_party/parsedatetime.zip https://codeload.github.com/bear/parsedatetime/zip/master\n(cd third_party; unzip parsedatetime.zip)\n(cd app; ln -s ../third_party/parsedatetime-master/parsedatetime)\n\n# Google API Client Library for Python\ncurl -o - https://google-api-python-client.googlecode.com/files/google-api-python-client-1.2.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/google-api-python-client-1.2/apiclient)\n(cd app; ln -s ../third_party/google-api-python-client-1.2/oauth2client)\n(cd app; ln -s ../third_party/google-api-python-client-1.2/uritemplate)\n\n# httplib2\ncurl -o - https://httplib2.googlecode.com/files/httplib2-0.8.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/httplib2-0.8/python2/httplib2)\n\n# boto\ncurl -o - https://codeload.github.com/boto/boto/tar.gz/2.13.3 |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/boto-2.13.3/boto)\n\n# Markdown\ncurl -o - https://pypi.python.org/packages/source/M/Markdown/Markdown-2.2.0.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/Markdown-2.2.0/markdown)\n\n# Pygments\ncurl -o - https://bitbucket.org/birkenfeld/pygments-main/get/1.5.tar.gz |\n    tar -zxv -C third_party -f -\n(cd app; ln -s ../third_party/birkenfeld-pygments-main-eff3aee4abff/pygments)\n\n# Now verify that everything was installed correctly.\n# You should have no hanging symlinks.\nls -ldL app/*\n```\n\n### Unit Tests\n\nRunning the bundled unit tests helps verify that all the libraries have been\ninstalled correctly. To run the unit tests locally you'll need to have the App\nEngine SDK libraries in your Python path.\n\n```shell\n# For example, suppose the App Engine SDK was installed in /usr/local/google_appengine\n\nGAE_PATH=/usr/local/google_appengine; export PYTHONPATH=$GAE_PATH:.; for fil in $GAE_PATH/lib/*; do export PYTHONPATH=$fil:$PYTHONPATH; done;\n```\n\nYou can run the unit tests with:\n\n```shell\n(cd app; python -m unittest discover src '*_test.py')\n```\n\nYou may see some warnings, but you should end up seeing all the tests\npassed OK. The last thing printed out should be how many tests ran and\nthen the text `OK`.\n\n### Installation\n\n1. Make an app at appengine.google.com (we use an app id of `example` for this\ndocument).\n\n2. [Enable billing].\n\n3. Set up a Google Cloud Storage bucket (if you don't have already have it,\n[install gsutil]. If you do have it, you might need to run\n`gsutil config `to set up the credentials):\n\n```shell\ngsutil mb gs://example/\ngsutil acl ch -u example@appspot.gserviceaccount.com:FC  gs://example\ngsutil defacl ch -u example@appspot.gserviceaccount.com:FC  gs://example\ngsutil cp app/static/examples/languagecodes.csv gs://example\n```\n\n\n4. Go to `Application Setting` for your app on appengine.google.com\n\n5. Copy the service account `example@appspot.gserviceaccount.com`\n\n6. Click on the `Google APIs Console Project Number`Click on the Google APIs\nConsole Project Number\n\n7. Add the service account under `Permissions`.\n\n8. Click on `APIs and Auth` and turn on BigQuery, Google Cloud Storage and\nGoogle Cloud Storage JSON API.\n\n9. Replace the application name in the .yaml files. So for example, if your app\nis called example.appspot.com:\n\n```shell\nperl -p -i~ -e 's/INSERT_YOUR_APPLICATION_NAME_HERE/example/' app/app.yaml app/backend.yaml\n```\n\n\n1. Now publish your application:\n\n```shell\nappcfg.py update --oauth2 app/app.yaml app/backend.yaml\n```\n\n\n1. You can now connect to your application and verify it:\n\n    1. Click the little cog and add your default bucket of `gs://example` (be\n    sure to substitute your bucket name here). You probably want to add prefix\n    (e.g. `tmp/`) to isolate any temporary objects used to move data between\n    stages.\n\n    2. Now create a new pipeline and upload the contents of\n    *app/static/examples/gcstobigquery.json*.\n\n    3. Run the pipeline. It should successfully run to completion.\n\n    4. Go to [BigQuery] and view your dataset and table.\n\n### Set up a Hadoop Environment\n\nAs in the previous section, here we also assume `gs://example` for your bucket;\nand `gce-example` is a project that has enough quota for Google Compute Engine\nto host your Hadoop cluster. The quota size (instances and CPUs) depends on the\nHadoop cluster size you will be using. We can use the same project as we did for\nBigQuery. As before, the following script can be copied and pasted into a shell\nas-is:\n\n```shell\n# Setup variables\nBUCKET=gs://example  # Change this.\nPROJECT=gce-example  # Change this.\nPACKAGE_DIR=$BUCKET/hadoop\n\n# Download Hadoop\ncurl -O http://archive.apache.org/dist/hadoop/core/hadoop-1.2.1/hadoop-1.2.1.tar.gz\n\n# Download additional Debian packages required for Hadoop\nmkdir deb_packages\n\n(cd deb_packages ; curl -O http://security.debian.org/debian-security/pool/updates/main/o/openjdk-6/openjdk-6-jre-headless_6b27-1.12.6-1~deb7u1_amd64.deb)\n(cd deb_packages ; curl -O http://security.debian.org/debian-security/pool/updates/main/o/openjdk-6/openjdk-6-jre-lib_6b27-1.12.6-1~deb7u1_all.deb)\n(cd deb_packages ; curl -O http://http.us.debian.org/debian/pool/main/n/nss/libnss3-1d_3.14.3-1_amd64.deb)\n(cd deb_packages ; curl -O http://http.us.debian.org/debian/pool/main/n/nss/libnss3_3.14.3-1_amd64.deb)\n(cd deb_packages ; curl -O http://http.us.debian.org/debian/pool/main/c/ca-certificates-java/ca-certificates-java_20121112+nmu2_all.deb)\n(cd deb_packages ; curl -O http://http.us.debian.org/debian/pool/main/n/nspr/libnspr4_4.9.2-1_amd64.deb)\n(cd deb_packages ; curl -O http://http.us.debian.org/debian/pool/main/p/patch/patch_2.6.1-3_amd64.deb)\n\n# Download and setup Flask and other packages\nmkdir -p rpc_daemon\n\nln app/static/hadoop_scripts/rpc_daemon/__main__.py rpc_daemon/\nln app/static/hadoop_scripts/rpc_daemon/favicon.ico rpc_daemon/\n\ncurl -o - https://pypi.python.org/packages/source/F/Flask/Flask-0.9.tar.gz |\n    tar zxf - -C rpc_daemon/\ncurl -o - https://pypi.python.org/packages/source/J/Jinja2/Jinja2-2.6.tar.gz |\n    tar zxf - -C rpc_daemon/\ncurl -o - https://pypi.python.org/packages/source/W/Werkzeug/Werkzeug-0.8.3.tar.gz |\n    tar zxf - -C rpc_daemon/\n\n(\n  cd rpc_daemon ;\n  ln -s Flask-*/flask . ;\n  ln -s Jinja2-*/jinja2 . ;\n  ln -s Werkzeug-*/werkzeug . ;\n  zip -r ../rpc-daemon.zip __main__.py favicon.ico flask jinja2 werkzeug\n)\n\n# Create script package\ntar zcf hadoop_scripts.tar.gz -C app/static  \\\n    hadoop_scripts/gcs_to_hdfs_mapper.sh  \\\n    hadoop_scripts/hdfs_to_gcs_mapper.sh  \\\n    hadoop_scripts/mapreduce__at__master.sh\n\n# Create SSH key\nmkdir -p generated_files/ssh-key\nssh-keygen -t rsa -P '' -f generated_files/ssh-key/id_rsa\ntar zcf generated_files.tar.gz generated_files/\n\n# Upload to Google Cloud Storage\ngsutil -m cp -R hadoop-1.2.1.tar.gz deb_packages/ $PACKAGE_DIR/\ngsutil -m cp  \\\n    app/static/hadoop_scripts/startup-script.sh  \\\n    app/static/hadoop_scripts/*.patch  \\\n    hadoop_scripts.tar.gz  \\\n    generated_files.tar.gz  \\\n    rpc-daemon.zip  \\\n    $PACKAGE_DIR/\n\n# Setup a firewall rule\ngcutil --project=$PROJECT addfirewall datapipeline-hadoop  \\\n    --description=\"Hadoop for Datapipeline\"  \\\n    --allowed=\"tcp:50070,tcp:50075,tcp:50030,tcp:50060,tcp:80\"\n```\n\nIn order for this App Engine application to launch Google Compute Engine\ninstances in the project, the service account of the App Engine application must\nbe granted `edit` permissions. To do this, follow these steps:\n\n1. Go to `Application Settings` on in the App Engine console and copy the value\n(should be an email address) indicated the `Service Account Name` field.\n\n2. Go to the [Cloud Console] of the project for which Google\nCompute Engine will be used.\n\n3. Go to the `Permissions` page, and click the red `ADD MEMBER` button on the\ntop.\n\n4. Paste the value from step #1 as the email address. Make sure the account has\n`can edit` permission.  Click the `Add` button to save the change.\n\n\n\n[Google Cloud Platform]: https://cloud.google.com/\n[Google App Engine]: https://cloud.google.com/products/app-engine\n[Amazon S3]: http://aws.amazon.com/s3/\n[Google Cloud Storage]: https://cloud.google.com/products/cloud-storage\n[Google Cloud Datastore]: https://developers.google.com/datastore/\n[Apache Hadoop]: http://hadoop.apache.org/\n[Google Compute Engine]: https://cloud.google.com/products/compute-engine\n[Google App Engine Pipeline API]: http://code.google.com/p/appengine-pipeline/\n[Google BigQuery]: https://cloud.google.com/products/big-query\n[http://www.apache.org/licenses/LICENSE-2.0]: http://www.apache.org/licenses/LICENSE-2.0\n[installation instructions]: https://developers.google.com/appengine/downloads#Google_App_Engine_SDK_for_Python\n[Enable billing]: https://developers.google.com/appengine/docs/pricing#first_time\n[install gsutil]: https://developers.google.com/storage/docs/gsutil_install\n[BigQuery]: https://bigquery.cloud.google.com/\n[Cloud Console]: https://cloud.google.com/console\n\n","undoManager":{"mark":-1,"position":36,"stack":[[{"group":"doc","deltas":[{"start":{"row":2,"column":11},"end":{"row":3,"column":0},"action":"insert","lines":["",""]},{"start":{"row":3,"column":0},"end":{"row":3,"column":0},"action":"insert","lines":[""]}]}],[{"group":"doc","deltas":[{"start":{"row":3,"column":0},"end":{"row":4,"column":0},"action":"insert","lines":["",""]},{"start":{"row":4,"column":0},"end":{"row":4,"column":0},"action":"insert","lines":[""]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":0},"end":{"row":4,"column":1},"action":"insert","lines":["#"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":1},"end":{"row":4,"column":2},"action":"insert","lines":["#"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":2},"end":{"row":4,"column":3},"action":"insert","lines":["#"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":3},"end":{"row":4,"column":4},"action":"insert","lines":["#"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":2},"end":{"row":4,"column":3},"action":"insert","lines":["t"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":3},"end":{"row":4,"column":4},"action":"insert","lines":["r"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":4},"end":{"row":4,"column":5},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":5},"end":{"row":4,"column":6},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":6},"end":{"row":4,"column":7},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":7},"end":{"row":4,"column":8},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":7},"end":{"row":4,"column":8},"action":"remove","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":6},"end":{"row":4,"column":7},"action":"remove","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":5},"end":{"row":4,"column":6},"action":"remove","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":4},"end":{"row":4,"column":5},"action":"remove","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":4},"end":{"row":4,"column":5},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":5},"end":{"row":4,"column":6},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":6},"end":{"row":4,"column":7},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":7},"end":{"row":4,"column":8},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":8},"end":{"row":4,"column":9},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":9},"end":{"row":4,"column":10},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":10},"end":{"row":4,"column":11},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":11},"end":{"row":4,"column":12},"action":"insert","lines":[" "]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":12},"end":{"row":4,"column":13},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":12},"end":{"row":4,"column":13},"action":"remove","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":11},"end":{"row":4,"column":12},"action":"remove","lines":[" "]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":11},"end":{"row":4,"column":12},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":12},"end":{"row":4,"column":13},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":13},"end":{"row":4,"column":14},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":14},"end":{"row":4,"column":15},"action":"insert","lines":["l"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":15},"end":{"row":4,"column":16},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":16},"end":{"row":4,"column":17},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":17},"end":{"row":4,"column":18},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":18},"end":{"row":4,"column":19},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":19},"end":{"row":4,"column":20},"action":"insert","lines":["a"]}]}],[{"group":"doc","deltas":[{"start":{"row":4,"column":20},"end":{"row":4,"column":21},"action":"insert","lines":[" "]}]}]]},"ace":{"folds":[],"scrolltop":0,"scrollleft":0,"selection":{"start":{"row":4,"column":21},"end":{"row":4,"column":21},"isBackwards":false},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1417445969312}